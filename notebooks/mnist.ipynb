{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_example import MNISTModel, MNISTDataModule\n",
    "\n",
    "datamodule = MNISTDataModule(batch_size=10)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from energizer.datamodule import ActiveDataModule\n",
    "\n",
    "dm = ActiveDataModule(datamodule=datamodule)\n",
    "dm.setup()\n",
    "dm.setup_folds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fe88ef97690>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     len(dm.pool_fold), \n",
    "#     len(dm.test_dataloader()),\n",
    "#     len(dm.train_fold), \n",
    "#     len(dm.train_dataloader()),\n",
    "# )\n",
    "# dm.label(list(range(100)))\n",
    "# print(\n",
    "#     len(dm.pool_fold), \n",
    "#     len(dm.test_dataloader()),\n",
    "#     len(dm.train_fold), \n",
    "#     len(dm.train_dataloader()),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from energizer.strategies.strategies import EntropyStrategy\n",
    "from energizer.strategies.inference import MCDropout, Deterministic\n",
    "from pytorch_lightning import LightningModule, Trainer as pl_Trainer\n",
    "from energizer.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(\n",
    "    [datamodule.mnist_test[i] for i in range(10)], \n",
    "    shuffle=False, \n",
    "    batch_size=2,\n",
    ")\n",
    "x, y = next(iter(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel()\n",
    "adapter = MCDropout(model)\n",
    "strategy = EntropyStrategy(adapter, 3)\n",
    "dm = ActiveDataModule(datamodule=datamodule)\n",
    "dm.setup()\n",
    "dm.setup_folds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.pool_fold), len(dm.train_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.train_dataloader().batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                | Type           | Params\n",
      "-------------------------------------------------------\n",
      "0 | adapter             | MCDropout      | 184 K \n",
      "1 | accumulation_metric | AccumulateTopK | 0     \n",
      "-------------------------------------------------------\n",
      "184 K     Trainable params\n",
      "0         Non-trainable params\n",
      "184 K     Total params\n",
      "0.738     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pietrolesci/miniconda3/envs/energizer-dev/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/Users/pietrolesci/miniconda3/envs/energizer-dev/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool Evaluation DataLoader 0:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "batch_idx: 0\n",
      "len: 100\n",
      "requires grad: True True\n",
      "current batch_size: 10\n",
      "current_indices: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "size: tensor(10)\n",
      "all_scores: tensor([  -inf,   -inf,   -inf, 2.2734, 2.2636, 2.2928, 2.2638, 2.2684, 2.2820,\n",
      "        2.2802, 2.2799, 2.2611, 2.2778], grad_fn=<CatBackward0>)\n",
      "all_indices: tensor([-1, -1, -1,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9])\n",
      "top_scores: tensor([2.2928, 2.2820, 2.2802], grad_fn=<TopkBackward0>)\n",
      "top_indices: tensor([2, 5, 6]) \n",
      "\n",
      "Pool Evaluation DataLoader 0:  10%|█         | 1/10 [00:00<00:00, 17.27it/s]\n",
      "batch_idx: 1\n",
      "len: 100\n",
      "requires grad: True True\n",
      "current batch_size: 10\n",
      "current_indices: tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
      "size: tensor(20)\n",
      "all_scores: tensor([2.2928, 2.2820, 2.2802, 2.2630, 2.2674, 2.2586, 2.2328, 2.2534, 2.2448,\n",
      "        2.2757, 2.2802, 2.2662, 2.2753], grad_fn=<CatBackward0>)\n",
      "all_indices: tensor([ 2,  5,  6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
      "top_scores: tensor([2.2928, 2.2820, 2.2802], grad_fn=<TopkBackward0>)\n",
      "top_indices: tensor([2, 5, 6]) \n",
      "\n",
      "Pool Evaluation DataLoader 0:  20%|██        | 2/10 [00:00<00:00, 29.37it/s]\n",
      "batch_idx: 2\n",
      "len: 100\n",
      "requires grad: True True\n",
      "current batch_size: 10\n",
      "current_indices: tensor([20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "size: tensor(30)\n",
      "all_scores: tensor([2.2928, 2.2820, 2.2802, 2.2696, 2.2836, 2.2428, 2.2585, 2.2735, 2.2598,\n",
      "        2.2326, 2.2836, 2.2841, 2.2725], grad_fn=<CatBackward0>)\n",
      "all_indices: tensor([ 2,  5,  6, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "top_scores: tensor([2.2928, 2.2841, 2.2836], grad_fn=<TopkBackward0>)\n",
      "top_indices: tensor([ 2, 28, 21]) \n",
      "\n",
      "Pool Evaluation DataLoader 0:  30%|███       | 3/10 [00:00<00:00, 39.23it/s]\n",
      "batch_idx: 3\n",
      "len: 100\n",
      "requires grad: True True\n",
      "current batch_size: 10\n",
      "current_indices: tensor([30, 31, 32, 33, 34, 35, 36, 37, 38, 39])\n",
      "size: tensor(40)\n",
      "all_scores: tensor([2.2928, 2.2841, 2.2836, 2.2528, 2.2747, 2.2506, 2.2296, 2.2768, 2.2594,\n",
      "        2.2720, 2.2895, 2.2547, 2.2940], grad_fn=<CatBackward0>)\n",
      "all_indices: tensor([ 2, 28, 21, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39])\n",
      "top_scores: tensor([2.2940, 2.2928, 2.2895], grad_fn=<TopkBackward0>)\n",
      "top_indices: tensor([39,  2, 37]) \n",
      "\n",
      "Pool Evaluation DataLoader 0:  40%|████      | 4/10 [00:00<00:00, 47.23it/s]\n",
      "batch_idx: 4\n",
      "len: 100\n",
      "requires grad: True True\n",
      "current batch_size: 10\n",
      "current_indices: tensor([40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "size: tensor(50)\n",
      "all_scores: tensor([2.2940, 2.2928, 2.2895, 2.2833, 2.2895, 2.2812, 2.2513, 2.2579, 2.2473,\n",
      "        2.2799, 2.2681, 2.2867, 2.2032], grad_fn=<CatBackward0>)\n",
      "all_indices: tensor([39,  2, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "top_scores: tensor([2.2940, 2.2928, 2.2895], grad_fn=<TopkBackward0>)\n",
      "top_indices: tensor([39,  2, 37]) \n",
      "\n",
      "Pool Evaluation DataLoader 0:  50%|█████     | 5/10 [00:00<00:00, 53.51it/s]\n",
      "batch_idx: 5\n",
      "len: 100\n",
      "requires grad: True True\n",
      "current batch_size: 10\n",
      "current_indices: tensor([50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "size: tensor(60)\n",
      "all_scores: tensor([2.2940, 2.2928, 2.2895, 2.2000, 2.1719, 2.1983, 2.2685, 2.2129, 2.2703,\n",
      "        2.2424, 2.2731, 2.2893, 2.2588], grad_fn=<CatBackward0>)\n",
      "all_indices: tensor([39,  2, 37, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])\n",
      "top_scores: tensor([2.2940, 2.2928, 2.2895], grad_fn=<TopkBackward0>)\n",
      "top_indices: tensor([39,  2, 37]) \n",
      "\n",
      "Pool Evaluation DataLoader 0:  60%|██████    | 6/10 [00:00<00:00, 59.01it/s]\n",
      "batch_idx: 6\n",
      "len: 100\n",
      "requires grad: True True\n",
      "current batch_size: 10\n",
      "current_indices: tensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69])\n",
      "size: tensor(70)\n",
      "all_scores: tensor([2.2940, 2.2928, 2.2895, 2.2721, 2.2702, 2.2840, 2.2835, 2.2590, 2.2333,\n",
      "        2.2728, 2.2460, 2.2279, 2.2582], grad_fn=<CatBackward0>)\n",
      "all_indices: tensor([39,  2, 37, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69])\n",
      "top_scores: tensor([2.2940, 2.2928, 2.2895], grad_fn=<TopkBackward0>)\n",
      "top_indices: tensor([39,  2, 37]) \n",
      "\n",
      "Pool Evaluation DataLoader 0:  70%|███████   | 7/10 [00:00<00:00, 63.87it/s]\n",
      "batch_idx: 7\n",
      "len: 100\n",
      "requires grad: True True\n",
      "current batch_size: 10\n",
      "current_indices: tensor([70, 71, 72, 73, 74, 75, 76, 77, 78, 79])\n",
      "size: tensor(80)\n",
      "all_scores: tensor([2.2940, 2.2928, 2.2895, 2.2333, 2.2595, 2.2351, 2.2901, 2.2902, 2.2549,\n",
      "        2.2731, 2.2746, 2.2876, 2.2714], grad_fn=<CatBackward0>)\n",
      "all_indices: tensor([39,  2, 37, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79])\n",
      "top_scores: tensor([2.2940, 2.2928, 2.2902], grad_fn=<TopkBackward0>)\n",
      "top_indices: tensor([39,  2, 74]) \n",
      "\n",
      "Pool Evaluation DataLoader 0:  80%|████████  | 8/10 [00:00<00:00, 67.56it/s]\n",
      "batch_idx: 8\n",
      "len: 100\n",
      "requires grad: True True\n",
      "current batch_size: 10\n",
      "current_indices: tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n",
      "size: tensor(90)\n",
      "all_scores: tensor([2.2940, 2.2928, 2.2902, 2.2545, 2.1732, 2.2457, 2.2798, 2.2732, 2.1797,\n",
      "        2.2506, 2.2424, 2.2912, 2.2885], grad_fn=<CatBackward0>)\n",
      "all_indices: tensor([39,  2, 74, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89])\n",
      "top_scores: tensor([2.2940, 2.2928, 2.2912], grad_fn=<TopkBackward0>)\n",
      "top_indices: tensor([39,  2, 88]) \n",
      "\n",
      "Pool Evaluation DataLoader 0:  90%|█████████ | 9/10 [00:00<00:00, 70.66it/s]\n",
      "batch_idx: 9\n",
      "len: 100\n",
      "requires grad: True True\n",
      "current batch_size: 10\n",
      "current_indices: tensor([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n",
      "size: tensor(100)\n",
      "all_scores: tensor([2.2940, 2.2928, 2.2912, 2.1703, 2.2806, 2.2835, 2.2582, 2.2750, 2.2472,\n",
      "        2.2721, 2.2058, 2.2668, 2.2611], grad_fn=<CatBackward0>)\n",
      "all_indices: tensor([39,  2, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n",
      "top_scores: tensor([2.2940, 2.2928, 2.2912], grad_fn=<TopkBackward0>)\n",
      "top_indices: tensor([39,  2, 88]) \n",
      "\n",
      "Pool Evaluation DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 72.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pietrolesci/miniconda3/envs/energizer-dev/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/Users/pietrolesci/miniconda3/envs/energizer-dev/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1931: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "compute indices: tensor([39,  2, 88])\n",
      "Epoch 0:   9%|▉         | 1/11 [00:00<00:00, 101.70it/s, loss=nan, v_num=296]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pietrolesci/miniconda3/envs/energizer-dev/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py:631: UserWarning: `training_step` must be implemented to be used with the Lightning Trainer\n",
      "  rank_zero_warn(\"`training_step` must be implemented to be used with the Lightning Trainer\")\n",
      "/Users/pietrolesci/miniconda3/envs/energizer-dev/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:137: UserWarning: `training_step` returned `None`. If this was on purpose, ignore this warning...\n",
      "  self.warning_cache.warn(\"`training_step` returned `None`. If this was on purpose, ignore this warning...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 11/11 [00:00<00:00, 92.34it/s, loss=nan, v_num=296] \n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=1, enable_progress_bar=True, total_budget=3)\n",
    "trainer.active_fit(strategy, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit_loop.done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                | Type           | Params\n",
      "-------------------------------------------------------\n",
      "0 | adapter             | MCDropout      | 184 K \n",
      "1 | accumulation_metric | AccumulateTopK | 0     \n",
      "-------------------------------------------------------\n",
      "184 K     Trainable params\n",
      "0         Non-trainable params\n",
      "184 K     Total params\n",
      "0.738     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    }
   ],
   "source": [
    "trainer.fit(strategy, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.current_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "195fd7177374df90e8fb0ddf6905c3c94c4a4300f1cc015456754f40bbdfd90b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('energizer-dev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
